{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1488cbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#packages i will be using\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import os \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6470633b",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'motor_data11-14lats.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\seans\\Documents\\GitHub\\ML_GROUP_2\\AIML Project Group 2.ipynb Cell 2\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/seans/Documents/GitHub/ML_GROUP_2/AIML%20Project%20Group%202.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#set object of both datasets\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/seans/Documents/GitHub/ML_GROUP_2/AIML%20Project%20Group%202.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m earlyYears \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39mmotor_data11-14lats.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/seans/Documents/GitHub/ML_GROUP_2/AIML%20Project%20Group%202.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m laterYears \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39mmotor_data14-2018.csv\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\seans\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\seans\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\seans\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Users\\seans\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1706\u001b[0m     f,\n\u001b[0;32m   1707\u001b[0m     mode,\n\u001b[0;32m   1708\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1709\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1710\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1711\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1712\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1713\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1714\u001b[0m )\n\u001b[0;32m   1715\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\seans\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    866\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    867\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    868\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'motor_data11-14lats.csv'"
     ]
    }
   ],
   "source": [
    "#set object of both datasets\n",
    "earlyYears = pd.read_csv('motor_data11-14lats.csv')\n",
    "laterYears = pd.read_csv('motor_data14-2018.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38914b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(earlyYears)\n",
    "display(laterYears)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a04572c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#can delete later\n",
    "earlyYears['SEATS_NUM'].unique()\n",
    "earlyYears[earlyYears['SEATS_NUM']== 120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a534177a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine both datasets to clean and then later split into test and validation sets once cleaned\n",
    "combined = pd.concat([earlyYears, laterYears], join = 'outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493b05aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if any null values\n",
    "combined.isna().any()\n",
    "#here we see that 8 columns have null values lets keep that in mind and go down the list understand each value in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0a073d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the allowed values in this column to see if anything stands out\n",
    "combined['SEX'].unique()\n",
    "s = []\n",
    "for i in combined['SEX']:\n",
    "    if i not in s:\n",
    "        s.append(i)\n",
    "        \n",
    "print(s)\n",
    "print(combined['SEX'].value_counts())\n",
    "\n",
    "#so it seems that there are 3 different values for sex unfortunately there is no metadata to understand this but maybe the data\n",
    "#could gives us a good assumption. for rn we will assume 0 = male 1 = female and 2 = other or unkown\n",
    "\n",
    "#correction after recieving\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a26e590",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346d8d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#look for the possible values of these columns\n",
    "display(combined['INSR_TYPE'].unique())\n",
    "display(combined['EFFECTIVE_YR'].unique())\n",
    "print(combined['INSR_TYPE'].value_counts())\n",
    "#it would seem that because of the wide variance of values in effective year and no metadata to help we might have to drop this\n",
    "#this column\n",
    "\n",
    "#insurance type is still up in the air on whether or not it should be used because of lack of metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6763ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76502d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change these values for easy plot \n",
    "combined['INSR_TYPE'] = combined['INSR_TYPE'].replace({1201: 'Private' , 1202: 'Commercial', 1204:'Motor trade road risk'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9994a586",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55861d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe410d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c100a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a figure and an array of subplots\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))  # 1 row, 2 columns\n",
    "\n",
    "# Get the value counts from the 'INSR_TYPE' column\n",
    "insr_type_counts = combined['INSR_TYPE'].value_counts()\n",
    "\n",
    "# Extract the values and counts\n",
    "values = insr_type_counts.index\n",
    "counts = insr_type_counts.values\n",
    "\n",
    "# Manually set x-axis positions for the specific values\n",
    "x_positions = [1, 2, 3]  # Adjust the positions as needed\n",
    "\n",
    "bar_width = 0.8  # Adjust the width of the bars\n",
    "bar1 = axs[0].bar(x_positions, counts, width=bar_width, align='center')\n",
    "\n",
    "#second plot look at the correlation between premium and capacity\n",
    "scat1 = axs[1].scatter(combined['PREMIUM'], combined['CARRYING_CAPACITY'])\n",
    "\n",
    "# Annotate each bar with its count value\n",
    "for bar, count in zip(bar1, counts):\n",
    "    yval = bar.get_height()\n",
    "    axs[0].text(bar.get_x() + bar.get_width()/2, yval, round(count, 2), ha='center', va='bottom')\n",
    "\n",
    "# Set x-axis ticks and labels\n",
    "axs[0].set_xticks(x_positions)\n",
    "axs[0].set_xticklabels(values)\n",
    "\n",
    "# Example: Plot something on the second subplot\n",
    "# right idea though axs[1].set_xticks(range(0, int(combined['PREMIUM'].max()) + 1000, 1000))\n",
    "axs[1].set_xlabel('PREMIUM')\n",
    "axs[1].set_ylabel('CARRYING_CAPACITY')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Adjust layout to prevent clipping of labels\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881abf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#some boolean masking to check to see which columns have the biggest amount of null values\n",
    "combined2 = combined[['SEX', 'INSR_BEGIN', 'INSR_END', 'EFFECTIVE_YR', 'INSR_TYPE',\n",
    "       'INSURED_VALUE', 'PREMIUM', 'OBJECT_ID', 'PROD_YEAR', 'SEATS_NUM',\n",
    "        'TYPE_VEHICLE', 'CCM_TON', 'MAKE', 'USAGE']]\n",
    "combined2[combined2.isna().any(axis=1)].reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ebf1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check just to make sure no columns were in one data set and not the other\n",
    "common_columns = set(earlyYears.columns) & set(laterYears.columns)\n",
    "\n",
    "columns_only_in_early = set(earlyYears.columns) - common_columns\n",
    "columns_only_in_later = set(laterYears.columns) - common_columns\n",
    "\n",
    "print(\"Columns only in earlyYears:\", columns_only_in_early)\n",
    "print(\"Columns only in laterYears:\", columns_only_in_later)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c5f368",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the dates and there formats\n",
    "\n",
    "date = combined['INSR_BEGIN']\n",
    "#string data type may want to convert them to date format \n",
    "type(date.iloc[0])\n",
    "\n",
    "date = date[:30]\n",
    "for i in date:\n",
    "    num = i[:2]\n",
    "    \n",
    "    print(num)\n",
    "#so it would seem my assumption of the first value is day so it would also seem to be formatted day/ mo abbrev/ year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055b942e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3db1820",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets check to see if all insurances begin and end within a year\n",
    "\n",
    "#first lets  \n",
    "from datetime import datetime\n",
    "\n",
    "combined['INSR_BEGIN'] = pd.to_datetime(combined['INSR_BEGIN'], format='%d-%b-%y')\n",
    "combined['INSR_END'] = pd.to_datetime(combined['INSR_END'], format='%d-%b-%y')\n",
    "\n",
    "# check to see if any dates are correct and not entry date incorrect \n",
    "combined[combined['INSR_BEGIN'] > combined['INSR_END']]\n",
    "\n",
    "combined['INSR_BEGIN'] - combined['INSR_END']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca07d53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined[combined['INSR_END'] - combined['INSR_BEGIN'] <  pd.Timedelta(days=364)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289876f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#understand the mean of dates for the dataset\n",
    "time= combined['INSR_END'] - combined['INSR_BEGIN']\n",
    "time.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f81bf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fd9295",
   "metadata": {},
   "outputs": [],
   "source": [
    "#see the unique values for type of vehicle\n",
    "combined['TYPE_VEHICLE'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6104051b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the values of type of vehicle to represent numerical values for ML purposes\n",
    "combined['TYPE_VEHICLE'] = combined['TYPE_VEHICLE'].replace({'Pick-up': 1, 'Station Wagones': 2, 'Truck': 3, 'Bus': 4, 'Automobile': 5,\n",
    "       'Tanker': 6, 'Trailers and semitrailers': 7, 'Motor-cycle': 8, 'Tractor': 9,\n",
    "       'Special construction': 10, 'Trade plates': 11})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6790e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#see the number of different make there are\n",
    "count = 0\n",
    "lis = []\n",
    "for i in combined['MAKE']:\n",
    "    if i not in lis:\n",
    "        lis.append(i)\n",
    "        count += 1 \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8764d617",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['USAGE'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efacf4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing nan values with 0 to use\n",
    "combined['CLAIM_PAID'] = combined['CLAIM_PAID'].replace({np.nan : 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2016111c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing values to numeric to use in ML model\n",
    "combined['USAGE'] = combined['USAGE'].replace({'Own Goods': 1 , 'Private': 2, 'General Cartage': 3, 'Fare Paying Passengers': 4,\n",
    "                              'Taxi': 5, 'Car Hires': 6, 'Own service': 7, 'Agricultural Own Farm': 8,\n",
    "                               'Special Construction': 9, 'Others': 10, 'Learnes': 11, 'Ambulance': 12,\n",
    "                               'Agricultural Any Farm': 13, 'Fire fighting': 14})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5874a16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#changes the values of make to numeric for ML model\n",
    "combined['MAKE'] = pd.factorize(combined['MAKE'])[0] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333e42c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combined['EFFECTIVE_YR'].unique())\n",
    "combined['EFFECTIVE_YR'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb30d5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing values using regex operators to be used in ML model\n",
    "combined['EFFECTIVE_YR'] = combined['EFFECTIVE_YR'].replace(['/', '-', 'B', 'S', 'R', 'EN', 'MO', 'IN', 'SS', 'RS', 'SR', 'EA', 'BS'], '', regex=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9569fab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "combined = combined.dropna(subset=['EFFECTIVE_YR'])\n",
    "\n",
    "\n",
    "combined['EFFECTIVE_YR'] = pd.to_numeric(combined['EFFECTIVE_YR'], errors='coerce')\n",
    "combined['EFFECTIVE_YR'].fillna(combined['EFFECTIVE_YR'].median(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f82657",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(combined[combined['EFFECTIVE_YR'] == 13])\n",
    "combined['EFFECTIVE_YR'].isna().any()\n",
    "combined['EFFECTIVE_YR'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650f8f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['SEATS_NUM'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dfff47",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined[combined['SEATS_NUM'] == 170]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67efcc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#store og variables\n",
    "combined2 = combined[['SEX', 'INSR_BEGIN', 'INSR_END', 'EFFECTIVE_YR', 'INSR_TYPE',\n",
    "       'INSURED_VALUE', 'OBJECT_ ID', 'PROD_YEAR', 'SEATS_NUM',\n",
    "        'TYPE_VEHICLE', 'CCM_TON', 'MAKE', 'USAGE']]\n",
    "# variables that can currently be used\n",
    "[['SEX', 'INSR_TYPE',\n",
    "       'INSURED_VALUE', 'OBJECT_ID', 'PROD_YEAR', 'SEATS_NUM','CARRYING_CAPACITY',\n",
    "        'TYPE_VEHICLE', 'CCM_TON', 'USAGE']]\n",
    "\n",
    "#low inpact\n",
    "'CLAIM_PAID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f67b06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#some boolean masking to check to see which columns have the biggest amount of null values\n",
    "combined2 = combined[['SEX', 'INSR_TYPE',\n",
    "       'INSURED_VALUE', 'OBJECT_ID', 'PROD_YEAR', 'SEATS_NUM','CARRYING_CAPACITY',\n",
    "        'TYPE_VEHICLE','MAKE', 'CCM_TON', 'USAGE']]\n",
    "combined2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c78622",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['PREMIUM'].min(), combined['PREMIUM'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3350f1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "premium_data = combined[\"PREMIUM\"]\n",
    "\n",
    "# Calculate the IQR\n",
    "Q1 = premium_data.quantile(0.25)\n",
    "Q3 = premium_data.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define the lower and upper bounds for outliers\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Identify outliers\n",
    "outliers = premium_data[(premium_data < lower_bound) | (premium_data > upper_bound)]\n",
    "\n",
    "# Count the number of outliers\n",
    "num_outliers = len(outliers)\n",
    "\n",
    "# Plot a boxplot with outliers highlighted\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(x=premium_data)\n",
    "plt.scatter(outliers.index, outliers, color='red', label='Outliers')\n",
    "plt.legend()\n",
    "plt.title('Boxplot with Outliers Highlighted')\n",
    "plt.show()\n",
    "\n",
    "# Print the number of outliers\n",
    "print(f\"Number of outliers: {num_outliers}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12aed46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers.mean(), combined['PREMIUM'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af9d40c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8230d541",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "selected_rows = combined[combined['INSURED_VALUE'] == 0]\n",
    "\n",
    "# Calculate the mean of selected rows\n",
    "mean_values = selected_rows.mean()\n",
    "\n",
    "# Set the display option for float format\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "# Display the mean values\n",
    "print(mean_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8b3e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#before changing dates \n",
    "# just to run a preliminary test on the data \n",
    "from sklearn.model_selection import train_test_split\n",
    "# Selecting features for the model\n",
    "X = combined2.dropna()[:603800]\n",
    "y = combined['PREMIUM'].dropna()[:603374]\n",
    "X_train, X_test, y_train, y_test,  = train_test_split(X, y, test_size=0.2 , random_state=42)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "model.predict(X_test)\n",
    "\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a273de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets also now test a decision tree\n",
    "# Import necessary libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Selecting features for the model\n",
    "X = combined[['SEX', \n",
    "       'INSURED_VALUE', 'OBJECT_ID', 'PROD_YEAR', 'SEATS_NUM',\n",
    "        'TYPE_VEHICLE', 'MAKE','CCM_TON',  'USAGE']].dropna()[:603800]\n",
    "y = combined['PREMIUM'].dropna()[:603800]\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Creating and training the decision tree model\n",
    "tree_model = DecisionTreeRegressor(random_state=42)\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions on the test set\n",
    "tree_predictions = tree_model.predict(X_test)\n",
    "\n",
    "# Evaluating the model using R-squared score\n",
    "tree_accuracy = r2_score(y_test, tree_predictions)\n",
    "\n",
    "# Print the R-squared score\n",
    "print(\"Decision Tree R-squared score:\", tree_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca7e968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "X = combined[['OBJECT_ID', 'USAGE', 'PROD_YEAR', 'PREMIUM', 'CCM_TON', 'TYPE_VEHICLE']].dropna()[:603800]\n",
    "y = combined['MAKE'].dropna()[:603800]\n",
    "\n",
    "# Encode categorical variables if needed (using one-hot encoding in this example)\n",
    "#X = pd.get_dummies(X, columns=['SEX', 'TYPE_VEHICLE', 'MAKE', 'USAGE'], drop_first=True)\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Creating and training the Random Forest model\n",
    "forest_model = RandomForestRegressor(random_state=42)\n",
    "forest_model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions on the test set\n",
    "forest_predictions = forest_model.predict(X_test)\n",
    "\n",
    "# Evaluating the model using R-squared score\n",
    "forest_accuracy = r2_score(y_test, forest_predictions)\n",
    "\n",
    "# Print the R-squared score\n",
    "print(\"Random Forest R-squared score:\", forest_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f51acd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#before date change\n",
    "[['USAGE','EFFECTIVE_YR',   'PROD_YEAR', 'SEX', 'MAKE', 'PREMIUM', 'CCM_TON', 'TYPE_VEHICLE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccc1391",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7877df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#in case we want to use these two columns\n",
    "from datetime import datetime\n",
    "combined['INSR_BEGIN_day'] = combined['INSR_BEGIN'].dt.day\n",
    "combined['INSR_BEGIN_month'] = combined['INSR_BEGIN'].dt.month\n",
    "combined['INSR_BEGIN_year'] = combined['INSR_BEGIN'].dt.year\n",
    "\n",
    "combined['INSR_END_day'] = combined['INSR_END'].dt.day\n",
    "combined['INSR_END_month'] = combined['INSR_END'].dt.month\n",
    "combined['INSR_END_year'] = combined['INSR_END'].dt.year\n",
    "\n",
    "\n",
    "\n",
    "# Selecting features for the model\n",
    "X = combined[['SEX', 'INSR_BEGIN_day', 'INSR_BEGIN_month', 'INSR_BEGIN_year', 'INSR_END_day', 'INSR_END_month', 'INSR_END_year', 'EFFECTIVE_YR', 'INSR_TYPE', 'PREMIUM', 'OBJECT_ID', 'PROD_YEAR', 'SEATS_NUM',\n",
    "       'CARRYING_CAPACITY', 'TYPE_VEHICLE', 'CCM_TON', 'MAKE', 'USAGE',\n",
    "       'CLAIM_PAID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d076587",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791a787b",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dffb1a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a357c00",
   "metadata": {},
   "source": [
    "# Will Need to get the accuracy of this up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d42f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = combined['PREMIUM'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9317c9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.array([2,2,1,1,2,1,2,1,2])\n",
    "wei = np.tile(weights, (X.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6754c1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just to run a preliminary test on the data \n",
    "from sklearn.model_selection import train_test_split\n",
    "# Selecting features for the model\n",
    "X = combined3\n",
    "y = Y[:603800]\n",
    "X_train, X_test, y_train, y_test, weight_train, weight_test = train_test_split(X, y, wei, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c5c0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "model.predict(X_test)\n",
    "\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef838389",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
